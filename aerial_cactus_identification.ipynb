{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "83dc067f1eaa4eda9f443cba3c064dbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d5a4ac1172ae45868912affa7486def5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1a419dc4c2304edb953f025df10ceb15",
              "IPY_MODEL_656b3e6e7535499db7c955236fdaec6b"
            ]
          }
        },
        "d5a4ac1172ae45868912affa7486def5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1a419dc4c2304edb953f025df10ceb15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cb3e6f2d889d4cbc945676aa9ae0679f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ba72cb4c2be4af48c4cdfb7f4af6b48"
          }
        },
        "656b3e6e7535499db7c955236fdaec6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_89c2a4bb40e146cfb955b732791356c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4000/4000 [00:05&lt;00:00, 743.93it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d90407e6bce4bec8605132cf3f9aba3"
          }
        },
        "cb3e6f2d889d4cbc945676aa9ae0679f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ba72cb4c2be4af48c4cdfb7f4af6b48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89c2a4bb40e146cfb955b732791356c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d90407e6bce4bec8605132cf3f9aba3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "colab": {
      "name": "aerial_cactus_identification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pOpEuaOv6p6Q"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0-xXPvsKPMK",
        "colab_type": "text"
      },
      "source": [
        "# 라이브러리 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7LB3mo-J9m_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 캐글\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tgB6q6VN3NoN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWdOIJdIKdIX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "0d30cde1-bdd7-4b59-a55c-e65c0f4f4e1b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G0CmUuAJ9nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# os.listdir('train')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Naq83qEP4EZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('/content/drive/My Drive/data/aerial-cactus-identification.zip')as zip_obj :\n",
        "  zip_obj.extractall()\n",
        "with ZipFile('/content/test.zip')as test_obj :\n",
        "  test_obj.extractall()\n",
        "with ZipFile('/content/train.zip')as train_obj :\n",
        "  train_obj.extractall()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUpbvkcL5EJQ",
        "colab_type": "text"
      },
      "source": [
        "## 데이터 확인"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU6nIYV75IAP",
        "colab_type": "text"
      },
      "source": [
        "## csv파일 확인\n",
        " - ```train.csv``` : id, has_cactus가 담겨 있으며 총 17500개의 데이터\n",
        "  - train데이터에 관한 csv\n",
        " - ```sample_submission.csv``` : 구성은 같으며 4000개의 데이터\n",
        "  - test데이터에 관한 csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_2p6F334ZXY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "8d1412ac-a569-4890-d6f2-fbe2451c9e48"
      },
      "source": [
        "df = pd.read_csv('/content/train.csv')\n",
        "print(df.head())\n",
        "\n",
        "file_list = df['id']\n",
        "has_cactus = df['has_cactus']\n",
        "print(len(file_list), len(has_cactus))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                     id  has_cactus\n",
            "0  0004be2cfeaba1c0361d39e2b000257b.jpg           1\n",
            "1  000c8a36845c0208e833c79c1bffedd1.jpg           1\n",
            "2  000d1e9a533f62e55c289303b072733d.jpg           1\n",
            "3  0011485b40695e9138e92d0b3fb55128.jpg           1\n",
            "4  0014d7a11e90b62848904c1418fc8cf2.jpg           1\n",
            "17500 17500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFdr3EMI4wq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "efb9ec17-9321-45ba-b0eb-4864657c2ad1"
      },
      "source": [
        "test_df = pd.read_csv('/content/sample_submission.csv')\n",
        "print(test_df.head())\n",
        "\n",
        "test_fnames = test_df['id']\n",
        "test_labels = test_df['has_cactus']\n",
        "\n",
        "print(len(test_fnames), len(test_labels))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                     id  has_cactus\n",
            "0  000940378805c44108d287872b2f04ce.jpg         0.5\n",
            "1  0017242f54ececa4512b4d7937d1e21e.jpg         0.5\n",
            "2  001ee6d8564003107853118ab87df407.jpg         0.5\n",
            "3  002e175c3c1e060769475f52182583d0.jpg         0.5\n",
            "4  0036e44a7e8f7218e9bc7bf8137e4943.jpg         0.5\n",
            "4000 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoESxlG256_5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "24addb74-020a-486e-db6d-420e0ec5ebb2"
      },
      "source": [
        "data_paths = glob('train/*.jpg')\n",
        "test_paths = glob('test/*.jpg')\n",
        "print(len(data_paths), len(test_paths))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17500 4000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLglHmoCE5er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "b14c2735-f1d6-4f1e-8833-345703762436"
      },
      "source": [
        "pa = glob('train/*.jpg')[0]\n",
        "pa\n",
        "g = tf.io.read_file(pa)\n",
        "im = tf.io.decode_image(g)\n",
        "print(im.shape)\n",
        "plt.imshow(im)\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au6Nu-N9FLJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (32, 32, 3)\n",
        "batch_size = 32"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozZkAooa6x4E",
        "colab_type": "text"
      },
      "source": [
        "하지만 케글에서 실습을 하면서 강사님께서 알려주신 방법은 다음과 같다  \n",
        "csv에서 ```id``` 열의 데이터를 활용해서 파일의 경로를 만들고 그에따른 label값을 ```has_cactus```열의 데이터로 만들었음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RiKP3Wi62A-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = 'train'\n",
        "\n",
        "data_paths = []\n",
        "for fname, label in zip(file_list, has_cactus) :\n",
        "  data_paths.append((os.path.join(data_dir, fname), label))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZDHY5kU6Hj_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "837793bf-6851-4db0-f1a5-472d7d3f89df"
      },
      "source": [
        "data_paths[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('train/0004be2cfeaba1c0361d39e2b000257b.jpg', 1),\n",
              " ('train/000c8a36845c0208e833c79c1bffedd1.jpg', 1),\n",
              " ('train/000d1e9a533f62e55c289303b072733d.jpg', 1),\n",
              " ('train/0011485b40695e9138e92d0b3fb55128.jpg', 1),\n",
              " ('train/0014d7a11e90b62848904c1418fc8cf2.jpg', 1),\n",
              " ('train/0017c3c18ddd57a2ea6f9848c79d83d2.jpg', 1),\n",
              " ('train/002134abf28af54575c18741b89dd2a4.jpg', 0),\n",
              " ('train/0024320f43bdd490562246435af4f90b.jpg', 0),\n",
              " ('train/002930423b9840e67e5a54afd4768a1e.jpg', 1),\n",
              " ('train/00351838ebf6dff6e53056e00a1e307c.jpg', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOpEuaOv6p6Q",
        "colab_type": "text"
      },
      "source": [
        "### ***학습을 할때 validatio_data가 있으면 좋은 것일까?***\n",
        "그전에 먼저 데이터에 대해서 알아본다  \n",
        "<br>\n",
        "#### 데이터의 종류\n",
        "- Train Data\n",
        " - 분석 모델을 만들기 위한 학습용 데이터이다\n",
        "- Validation Data\n",
        " - 여러 분석 모델 중 어떤 모델이 적합한지 선택하기 위한 검증용 데이터이다.\n",
        "- Test Data\n",
        " - 최종적으로 선택된 분석 모델이 얼마나 잘 작동하는지 확인하기 위한 결과용 데이터이다.<br>\n",
        "\n",
        "#### https://3months.tistory.com/118\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ4MYK1g-EAX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```python\n",
        "def read_data(path) :\n",
        "  gfile = tf.io.read_file(path)\n",
        "  image = tf.io.decode_image(gfile)\n",
        "\n",
        "  class_name = tf.strings.split(path, '/')[-1]\n",
        "  class_name = tf.strings.split(class_name, '_')[-1]\n",
        "  class_name = tf.strings.split(class_name, '.')[0]\n",
        "\n",
        "  onehot = tf.cast(labels == class_name, tf.uint8)\n",
        "\n",
        "  return image, onehot\n",
        "```\n",
        "\n",
        "기존의 read_data는 위의 함수의 형태로 되어 있었다. (mnist, cifar10)  \n",
        "mnist와 cifar와 같은 경우는 10개의 클래스로 분류하는 것\n",
        "하지만 이 데이터는\n",
        "- 입력된 사진으로 부터\n",
        "  - 선인장이 있는지\n",
        "  - 없는지\n",
        "2가지로 분류하는 것  \n",
        "\n",
        "- 이진분류? \n",
        " - 이진 분류에서 많이 사용하는 활성화함수 : ```sigmoid```\n",
        " - 다중 분류에서 많이 사용되는 활성화함수 : ```softmax```\n",
        " - 추가적으로 이진분류의 loss는 ```binary_crossentroy``` 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyvyH1pRCUDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tmp_func (path_name) :\n",
        "  return path_name"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsvawKTd_qHo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3bc3fc4b-9a47-4153-f78e-0659b8f08b73"
      },
      "source": [
        "a = tf.data.Dataset.from_tensor_slices(np.array(data_paths[:2]))\n",
        "a = a.map(tmp_func)\n",
        "p = next(iter(a))\n",
        "p[0], p[1]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(), dtype=string, numpy=b'train/0004be2cfeaba1c0361d39e2b000257b.jpg'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'1'>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdnl4VJE9kMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(path_name) :\n",
        "  img_path = path_name[0]\n",
        "  label = tf.strings.to_number(path_name[1], out_type=tf.int64)\n",
        "\n",
        "  gfile = tf.io.read_file(img_path)\n",
        "  image = tf.io.decode_image(gfile)\n",
        "  \n",
        "  return image, label"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zp3rq2gA61u",
        "colab_type": "text"
      },
      "source": [
        "이전에 만든 data_path에는 경로와 그에 따른 label값들이 들어가게 된다  \n",
        "이를 각각 경로를 통해서 image를 읽어들이는 것과 label값을 return하도록 만든다  \n",
        "<br>\n",
        "**근데 .... label값을 그대로 return 해줘도 되는가?**  \n",
        "<br>\n",
        "이게 제일 의문점이다.  \n",
        "image 자체는 ```tf.io.read_file```, ```tf.io.decode_image``` 기존에 사용했던 것들을 활용하면 되는 것  \n",
        "이전에 mnist나 cifar10 같은 경우는 각 입력값들로부터 onehot encoding을 통해서 결과를 return해주었지만 여기선 이진 분류이기 때문에 **선인장이 있는가? 없는가?**를 판단 하는 것이고 ......"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LN8H1AqD5a5",
        "colab_type": "text"
      },
      "source": [
        "[shuffle에서 buffer_size](https://helloyjam.github.io/tensorflow/buffer-size-in-shuffle/)\n",
        "\n",
        "이미지를 읽고 프로세싱하고 배치작업등의 무거운 작업을 하기 전에 tf.data.Dataset.shuffle()을 호출해야 한다  \n",
        "+. ```tf.data.Dataset.from_tensor_slices((파일목록, 라벨값))```\n",
        " - 파일목록과 라벨값으로 데이터셋을 만드는 것.... 기억해두자"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S3Cn2nVS3yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ratio = 0.8\n",
        "\n",
        "train_paths = data_paths[:int(train_ratio*len(data_paths))]\n",
        "test_paths = data_paths[int(train_ratio*len(data_paths)):]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94avpsdo_39O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(np.array(train_paths))\n",
        "train_ds = train_ds.map(read_data)\n",
        "# print(next(iter(train_ds)))\n",
        "# 이때 확인하면 image에 대한 tensor값과 그 이미지에 대한 라벨을 알 수 있음\n",
        "train_ds = train_ds.shuffle(len(train_paths))\n",
        "# shuffle에 대한 buffer_size에 관해서도(위에 참고)\n",
        "train_ds = train_ds.batch(batch_size)\n",
        "train_ds = train_ds.repeat()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLFoWAIhTsmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_ds = tf.data.Dataset.from_tensor_slices(np.array(test_paths))\n",
        "valid_ds = valid_ds.map(read_data)\n",
        "valid_ds = valid_ds.batch(batch_size)\n",
        "valid_ds = valid_ds.repeat()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8p-BN5jCgkH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = layers.Input(input_shape)\n",
        "\n",
        "# Feature extraction\n",
        "net = layers.Conv2D(32, 3, 1, 'SAME')(inputs)\n",
        "net = layers.Activation('relu')(net)\n",
        "net = layers.Conv2D(32, 3, 1, 'SAME')(net)\n",
        "net = layers.Activation('relu')(net)\n",
        "net = layers.MaxPooling2D((2, 2))(net)\n",
        "net = layers.Dropout(0.5)(net)\n",
        "\n",
        "net = layers.Conv2D(64, 3, 1, 'SAME')(net)\n",
        "net = layers.Activation('relu')(net)\n",
        "net = layers.Conv2D(64, 3, 1, 'SAME')(net)\n",
        "net = layers.Activation('relu')(net)\n",
        "net = layers.MaxPooling2D((2, 2))(net)\n",
        "net = layers.Dropout(0.5)(net)\n",
        "\n",
        "# classification\n",
        "net = layers.Flatten()(net)\n",
        "net = layers.Dense(512)(net)\n",
        "net = layers.Activation('relu')(net)\n",
        "net = layers.Dropout(0.5)(net)\n",
        "net = layers.Dense(1)(net)\n",
        "net = layers.Activation('sigmoid')(net)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=net, name='cactus_cnn')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yorC4uQCGWFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8b54bd28-2467-4484-ec86-519167f0f265"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"cactus_cnn\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 2,163,745\n",
            "Trainable params: 2,163,745\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln6e-2-zGYVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss = tf.keras.losses.binary_crossentropy,\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BMODvRqHTSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps_per_epoch = len(train_paths) // batch_size\n",
        "validation_steps = len(test_paths) // batch_size"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH-ijMFXHZ9I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6b7d499e-1293-416c-d824-0f0dd2ac6269"
      },
      "source": [
        "hist = model.fit(train_ds,\n",
        "                 validation_data=valid_ds,\n",
        "                 validation_steps=validation_steps,\n",
        "                 steps_per_epoch=steps_per_epoch,\n",
        "                 epochs = 30)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "437/437 [==============================] - 6s 14ms/step - loss: 0.6817 - accuracy: 0.8886 - val_loss: 0.1477 - val_accuracy: 0.9452\n",
            "Epoch 2/30\n",
            "437/437 [==============================] - 10s 24ms/step - loss: 0.1450 - accuracy: 0.9437 - val_loss: 0.0931 - val_accuracy: 0.9693\n",
            "Epoch 3/30\n",
            "437/437 [==============================] - 11s 25ms/step - loss: 0.1286 - accuracy: 0.9490 - val_loss: 0.0952 - val_accuracy: 0.9713\n",
            "Epoch 4/30\n",
            "437/437 [==============================] - 10s 23ms/step - loss: 0.1152 - accuracy: 0.9560 - val_loss: 0.1090 - val_accuracy: 0.9584\n",
            "Epoch 5/30\n",
            "437/437 [==============================] - 11s 25ms/step - loss: 0.0975 - accuracy: 0.9627 - val_loss: 0.0877 - val_accuracy: 0.9676\n",
            "Epoch 6/30\n",
            "437/437 [==============================] - 11s 26ms/step - loss: 0.0876 - accuracy: 0.9663 - val_loss: 0.0636 - val_accuracy: 0.9791\n",
            "Epoch 7/30\n",
            "437/437 [==============================] - 11s 26ms/step - loss: 0.0846 - accuracy: 0.9671 - val_loss: 0.0603 - val_accuracy: 0.9851\n",
            "Epoch 8/30\n",
            "437/437 [==============================] - 11s 26ms/step - loss: 0.0848 - accuracy: 0.9677 - val_loss: 0.0558 - val_accuracy: 0.9857\n",
            "Epoch 9/30\n",
            "437/437 [==============================] - 11s 25ms/step - loss: 0.0804 - accuracy: 0.9699 - val_loss: 0.0474 - val_accuracy: 0.9862\n",
            "Epoch 10/30\n",
            "  6/437 [..............................] - ETA: 4s - loss: 0.0697 - accuracy: 0.9635"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7bb7ecb28c42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                  \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                  epochs = 30)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4_opKadHfBf",
        "colab_type": "text"
      },
      "source": [
        "# 평가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uRJARc4WDwL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "48ba23c7-61de-486e-98d4-11ed591771fe"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>has_cactus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000940378805c44108d287872b2f04ce.jpg</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0017242f54ececa4512b4d7937d1e21e.jpg</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ee6d8564003107853118ab87df407.jpg</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>002e175c3c1e060769475f52182583d0.jpg</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0036e44a7e8f7218e9bc7bf8137e4943.jpg</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     id  has_cactus\n",
              "0  000940378805c44108d287872b2f04ce.jpg         0.5\n",
              "1  0017242f54ececa4512b4d7937d1e21e.jpg         0.5\n",
              "2  001ee6d8564003107853118ab87df407.jpg         0.5\n",
              "3  002e175c3c1e060769475f52182583d0.jpg         0.5\n",
              "4  0036e44a7e8f7218e9bc7bf8137e4943.jpg         0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccIZuxzzWG5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f4c2d7ea-fa3e-487f-9f1f-0abff2125709"
      },
      "source": [
        "test_fnames[:5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    000940378805c44108d287872b2f04ce.jpg\n",
              "1    0017242f54ececa4512b4d7937d1e21e.jpg\n",
              "2    001ee6d8564003107853118ab87df407.jpg\n",
              "3    002e175c3c1e060769475f52182583d0.jpg\n",
              "4    0036e44a7e8f7218e9bc7bf8137e4943.jpg\n",
              "Name: id, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXwSTsA7WYBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "178e99de-2727-45e7-90e4-b79677ca6c8f"
      },
      "source": [
        "test_labels[:5]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.5\n",
              "1    0.5\n",
              "2    0.5\n",
              "3    0.5\n",
              "4    0.5\n",
              "Name: has_cactus, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WduOySV7WcAv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2ca26955-cc2c-4aa6-ff40-0ef803fb844c"
      },
      "source": [
        "test_dir = 'test'\n",
        "\n",
        "eval_paths = []\n",
        "for fname in test_fnames :\n",
        "  eval_paths.append(os.path.join(test_dir, fname))\n",
        "\n",
        "print(eval_paths[:5])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['test/000940378805c44108d287872b2f04ce.jpg', 'test/0017242f54ececa4512b4d7937d1e21e.jpg', 'test/001ee6d8564003107853118ab87df407.jpg', 'test/002e175c3c1e060769475f52182583d0.jpg', 'test/0036e44a7e8f7218e9bc7bf8137e4943.jpg']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeqzMNzMWzgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def image_read(path) :\n",
        "  g = tf.io.read_file(path)\n",
        "  im = tf.io.decode_image(g)\n",
        "\n",
        "  return im"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIQXYuuacq-Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftduVgrDYLWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120,
          "referenced_widgets": [
            "83dc067f1eaa4eda9f443cba3c064dbe",
            "d5a4ac1172ae45868912affa7486def5",
            "1a419dc4c2304edb953f025df10ceb15",
            "656b3e6e7535499db7c955236fdaec6b",
            "cb3e6f2d889d4cbc945676aa9ae0679f",
            "5ba72cb4c2be4af48c4cdfb7f4af6b48",
            "89c2a4bb40e146cfb955b732791356c1",
            "5d90407e6bce4bec8605132cf3f9aba3"
          ]
        },
        "outputId": "e20cd596-3c88-4840-94ea-09c69d3b587b"
      },
      "source": [
        "# test_images = [image_read(path) for path in eval_paths]\n",
        "\n",
        "test_images = []\n",
        "for path in tqdm_notebook(eval_paths) :\n",
        "  test_images.append(image_read(path))\n",
        "\n",
        "# np.array(test_image).shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83dc067f1eaa4eda9f443cba3c064dbe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epdrpNHfdC38",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = tf.data.Dataset.from_tensor_slices(eval_paths)\n",
        "test_ds = test_ds.map(image_read)\n",
        "test_ds = test_ds.batch(batch_size)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZMWeaAAYXgv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict(test_ds)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iosjnJ3FYnT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c4a13c8c-f383-47e6-bdfd-c05dc44b2928"
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQvkvFzk6R-o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pred.reshape((4000))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ_ZYY5Z6wDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# submit_df = pd.read_csv('../input/aerial-cactus-identification/sample_submission.csv')\n",
        "submit_df = pd.read_csv('/content/sample_submission.csv')\n",
        "test_fnames = submit_df['id']\n",
        "test_labels = pred  # 결과가 onehot이 아닌 binary로 담아줘야함\n",
        "\n",
        "submit_file = pd.DataFrame({'id':test_fnames, 'has_cactus':test_labels}, columns = ['id', 'has_cactus'])\n",
        "submit_file\n",
        "submit_file.to_csv('submission.csv', index=False)"
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}